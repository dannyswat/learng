# AI Coding Agent Instructions for `learng`

## Project Mission
Build an AI-powered language learning web app for kids (ages 5-12) that automatically generates rich multimedia content (images + pronunciation audio) from simple word/phrase inputs, organizes vocabulary into themed journeys, and tracks individual learner mastery.

## Current State (Pre-Implementation)
- **Phase**: Requirements defined; tech stack selection pending
- **Documents**: `REQUIREMENT.md` (business requirements), `AI ANALYSIS.md` (AI provider comparison)
- **Region**: Hong Kong-based; target Asia-Pacific latency; initial languages: Cantonese/Mandarin/English pairs
- **No code yet**: First implementation pass should establish stack, directory structure, and scaffold MVP features

## Strategic Context (Read First)
- **Differentiator**: Admin enters words ‚Üí AI auto-generates kid-safe images + TTS audio ‚Üí learners consume via card-based UI
- **Safety-Critical**: All generated media must pass moderation (child audience)
- **Cost-Sensitive**: Target <$0.10/word generation cost; plan caching + eventual hybrid self-hosting
- **Agile**: Functional specs evolve iteratively; this doc + REQUIREMENT.md are strategic anchors

## Architecture Principles (Intended)
1. **Modular AI Adapters**: Abstract image/audio/LLM providers behind interfaces to enable hot-swapping (Azure ‚Üí Stability, ElevenLabs ‚Üí Azure TTS, etc.)
2. **Async-First Generation**: Queue AI jobs; never block admin UI on generation latency
3. **Safety Pipeline**: Input validation ‚Üí Prompt refinement (LLM) ‚Üí Generation ‚Üí Moderation ‚Üí Storage
4. **Progressive Enhancement**: Responsive web (MVP) ‚Üí PWA offline (Phase 2) ‚Üí native apps (future)
5. **Privacy-by-Design**: Minimal PII; learner progress tracked with pseudonymous IDs

## Recommended Tech Stack (Pending Confirmation)
**Awaiting stakeholder decision; default assumption for scaffolding:**
- **Frontend**: Next.js (App Router) + React + TypeScript + Tailwind CSS
- **Backend**: Node.js + Express/Fastify (or Next.js API routes) + TypeScript
- **Database**: PostgreSQL (via Prisma ORM) for relational data + audit log
- **Queue**: BullMQ (Redis-backed) for async AI job processing
- **Storage**: Cloud object storage (Azure Blob or S3-compatible) + CDN
- **AI Providers (MVP)**: Azure OpenAI (image + LLM), Azure TTS or ElevenLabs (audio), Azure Content Safety (moderation)
- **Deployment**: Docker-compose (local) ‚Üí Azure Container Apps or Vercel + separate worker service (production)

## Directory Structure (Proposed Once Stack Chosen)
```
learng/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ web/            # Next.js frontend (learner + admin UI)
‚îÇ   ‚îî‚îÄ‚îÄ worker/         # AI generation job processor
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ ai-adapters/    # Provider abstraction layer
‚îÇ   ‚îú‚îÄ‚îÄ db/             # Prisma schema + migrations
‚îÇ   ‚îî‚îÄ‚îÄ shared/         # Common types, utils, constants
‚îú‚îÄ‚îÄ docs/               # Architecture decisions, API specs
‚îú‚îÄ‚îÄ scripts/            # Setup, seed data, cost analysis
‚îî‚îÄ‚îÄ .github/            # CI workflows, this file
```

## Core Data Model (High-Level)
- **Journey** (1) ‚Üí **Scenarios** (N) ‚Üí **Words** (N) ‚Üí **MediaAssets** (N per word)
- **User** (learner/admin roles) ‚Üí **Mastery** (user √ó word progress)
- **QuizSession** ‚Üí **QuizQuestions** (quiz attempts + scoring)
- **Events** (append-only audit log)
- **GenerationJobs** (queue tasks: pending ‚Üí processing ‚Üí completed|failed)

## AI Integration Patterns (Critical)
**All AI calls must follow this flow:**
1. **Prompt Refinement**: Admin word ‚Üí LLM generates descriptive, kid-safe visual prompt + alt text
2. **Enqueue Jobs**: Create `generation_jobs` records (image + audio) with status=pending
3. **Worker Polls Queue**: Fetch job ‚Üí call provider adapter ‚Üí store result/error
4. **Moderation Gate**: Before marking asset ready, run safety check; flag/quarantine unsafe outputs
5. **Status Updates**: Emit events for admin UI live status (polling or WebSocket)

**Provider Adapter Interface (conceptual TypeScript):**
```typescript
interface ImageGenAdapter {
  generate(req: ImageGenRequest): Promise<ImageGenResult>;
}
interface AudioTTSAdapter {
  synthesize(req: AudioRequest): Promise<AudioResult>;
}
// Implementations: AzureImageAdapter, StabilityImageAdapter, ElevenLabsTTSAdapter, AzureTTSAdapter
```

## Testing Strategy (MVP Baseline)
- **Unit**: AI adapter logic, prompt templates, mastery calculation
- **Integration**: API endpoints (journey CRUD, quiz scoring), job queue processing
- **E2E (manual initially)**: Admin creates word ‚Üí verify AI generation ‚Üí learner views card ‚Üí takes quiz
- **Safety Tests**: Submit edge-case prompts; verify moderation catches inappropriate outputs

## Security & Compliance (Non-Negotiable)
- Store API keys in environment variables / Azure Key Vault (never commit)
- Hash passwords (bcrypt); use JWT or session cookies for auth
- Rate-limit admin regeneration endpoints to prevent cost abuse
- Log all AI requests (prompt + provider + cost estimate) for audit
- Anonymize learner analytics (no direct PII in aggregate reports)

## Conventions (Evolving)
**Once code is written, update this section with discovered patterns:**
- Error handling: Structured errors with codes (e.g., `AI_GENERATION_FAILED`, `MODERATION_FLAGGED`)
- Logging: Structured JSON (trace IDs per request/job)
- Config: `.env.example` with all required vars; validate on startup with Zod/Joi
- Naming: `camelCase` (TS/JS), `snake_case` (DB columns), `kebab-case` (files/folders)

## When Adding New Features
1. Check if AI provider abstraction is affected ‚Üí update interface first
2. Add DB migration if schema changes (version journeys to avoid breaking published content)
3. Update `REQUIREMENT.md` if business scope shifts
4. Add cost telemetry if new AI call introduced (track tokens/chars/images)
5. Consider safety implications (new user input? ‚Üí sanitize; new AI output? ‚Üí moderate)

## Cost Control Techniques (Apply Everywhere)
- Cache AI outputs: hash(prompt+style) ‚Üí check DB before calling provider
- Batch operations: Admin bulk-adds 50 words ‚Üí enqueue all jobs, respect rate limits
- Fallback tiers: Expensive model fails/quotas exhausted ‚Üí cheaper fallback (e.g., GPT-4o ‚Üí GPT-4o-mini)
- Monitoring: Daily cost counter; soft alert at 80% budget; hard stop at 100%

## Open Questions to Resolve Before Deep Coding
- Exact language pairs for MVP? (Recommend: English‚ÜîCantonese pilot)
- Azure subscription + OpenAI quota approved?
- Admin auth: OAuth (Google) or simple email/password?
- Hosting preference: Vercel, Azure Container Apps, or other?
- Budget ceiling for MVP phase AI spend?

## Development Workflow (Once Stack Established)
```bash
# Local setup (example commands, adjust per stack)
npm install                     # Install dependencies
npx prisma migrate dev          # Run DB migrations
npm run dev                     # Start Next.js + worker (concurrently)
npm run test                    # Run test suite
npm run lint                    # ESLint + Prettier
```

## CI/CD Expectations
- **PR Checks**: Lint, type-check, unit tests, build verification
- **Main Branch**: Auto-deploy to staging environment
- **Production**: Manual approval gate (until stable)

## Related Documents (Read for Context)
- `REQUIREMENT.md` ‚Äì Business goals, user journeys, success metrics, phasing
- `AI ANALYSIS.md` ‚Äì Provider comparison, safety pipeline, cost strategies, regional constraints
- Future: `ARCHITECTURE.md` (system design), `API_SPEC.md` (OpenAPI/GraphQL schema), `USER_STORIES.md` (sprint backlog)

## AI Agent Best Practices for This Project
- **Safety First**: When generating prompts or handling user input, always apply sanitization/validation
- **Cost Awareness**: Prefer cheaper models (e.g., gpt-4o-mini over gpt-4o) unless quality explicitly requires premium
- **Async by Default**: Never block HTTP responses on AI generation; use job queue + status polling
- **Regional Respect**: Suggest Asia-Pacific regions (Hong Kong, Singapore) for deployments/AI endpoints
- **Test AI Paths**: When adding adapter implementations, include mock/stub tests to avoid live API costs in CI

## Documentation Guidelines (IMPORTANT)
**Keep documentation minimal and consolidated:**

### ‚úÖ DO Create/Update:
1. **PROJECT_STATUS.md** (root) - Single source of truth for overall project status
   - Sprint progress tracker
   - Current phase and next steps
   - High-level file inventory
   - Key metrics

2. **README.md** (per directory) - Quick start and setup only
   - Installation steps
   - How to run/test
   - Basic usage examples
   - Links to PROJECT_STATUS.md

3. **Test Scripts** - Executable documentation
   - Self-documenting test files (e.g., `test-sprint2.sh`)
   - Include comments explaining what's being tested
   - Better than separate test documentation

4. **Code Comments** - Inline documentation
   - Complex logic explanations
   - API endpoint documentation (OpenAPI/Swagger comments)
   - Function/class docstrings

### ‚ùå DO NOT Create:
- ‚ùå Separate files for each sprint (e.g., `SPRINT2_SUMMARY.md`, `SPRINT2_COMPLETE.md`)
- ‚ùå Multiple "index" or "guide" files (e.g., `SPRINT2_INDEX.md`, `SPRINT2_QUICK_REF.md`)
- ‚ùå Redundant status files (e.g., `TEST_RESULTS.md`, `TEST_RESULTS_SPRINT2.md`)
- ‚ùå "CREATION_SUMMARY.md" or similar scaffolding documentation
- ‚ùå Multiple reference guides (consolidate into README or PROJECT_STATUS)
- ‚ùå Files that duplicate information from other docs

### üìù Documentation Updates:
- **When starting a sprint**: Update PROJECT_STATUS.md with new tasks
- **When completing a sprint**: Update PROJECT_STATUS.md with results, keep sprint notes in comments
- **When adding features**: Update relevant README.md, add inline code comments
- **When testing**: Use test scripts as executable documentation

### üóÇÔ∏è Approved Documentation Structure:
```
learng/
‚îú‚îÄ‚îÄ PROJECT_STATUS.md          # Single source of truth
‚îú‚îÄ‚îÄ REQUIREMENT.md             # Business requirements (don't modify)
‚îú‚îÄ‚îÄ README.md                  # Project setup
‚îú‚îÄ‚îÄ design/
‚îÇ   ‚îú‚îÄ‚îÄ CORE.md               # Technical specification
‚îÇ   ‚îî‚îÄ‚îÄ SUMMARY.md            # Design summary
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ README.md             # Backend setup and API reference
‚îÇ   ‚îî‚îÄ‚îÄ test-*.sh             # Executable test documentation
‚îî‚îÄ‚îÄ frontend/
    ‚îî‚îÄ‚îÄ README.md             # Frontend setup and component guide
```

### üìä When Asked to Document Progress:
1. Update PROJECT_STATUS.md with bullet points
2. Update relevant README.md if setup changed
3. Add comments to test scripts
4. **DO NOT** create new markdown files unless absolutely necessary

---
**Last Updated**: 2025-10-08 | **Current Stack**: Go + Echo + GORM + React + Vite
